//Professional terraform tutorial

majorly we use in terraform 3 files
1. main.tf or vpc.tf
2.variable.tf
3.terra.tfvars

reference github url:
https://github.com/mavrick202/terraformsingleinstance

above code main.tf file is
===========================================================
#This Terraform Code Deploys Basic VPC Infra.
provider "aws" {
    access_key = "${var.aws_access_key}"
    secret_key = "${var.aws_secret_key}"
    region = "${var.aws_region}"
}

resource "aws_vpc" "default" {
    cidr_block = "${var.vpc_cidr}"
    enable_dns_hostnames = true
    tags = {
        Name = "${var.vpc_name}"
	Owner = "Sreeharsha Veerapalli"
	environment = "${var.environment}"
    }
}

resource "aws_internet_gateway" "default" {
    vpc_id = "${aws_vpc.default.id}"
	tags = {
        Name = "${var.IGW_name}"
    }
}

resource "aws_subnet" "subnet1-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet1_cidr}"
    availability_zone = "us-east-1a"

    tags = {
        Name = "${var.public_subnet1_name}"
    }
}

resource "aws_subnet" "subnet2-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet2_cidr}"
    availability_zone = "us-east-1b"

    tags = {
        Name = "${var.public_subnet2_name}"
    }
}

resource "aws_subnet" "subnet3-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet3_cidr}"
    availability_zone = "us-east-1c"

    tags = {
        Name = "${var.public_subnet3_name}"
    }
	
}


resource "aws_route_table" "terraform-public" {
    vpc_id = "${aws_vpc.default.id}"

    route {
        cidr_block = "0.0.0.0/0"
        gateway_id = "${aws_internet_gateway.default.id}"
    }

    tags = {
        Name = "${var.Main_Routing_Table}"
    }
}

resource "aws_route_table_association" "terraform-public" {
    subnet_id = "${aws_subnet.subnet1-public.id}"
    route_table_id = "${aws_route_table.terraform-public.id}"
}

resource "aws_security_group" "allow_all" {
  name        = "allow_all"
  description = "Allow all inbound traffic"
  vpc_id      = "${aws_vpc.default.id}"

  ingress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port       = 0
    to_port         = 0
    protocol        = "-1"
    cidr_blocks     = ["0.0.0.0/0"]
    }
}

# data "aws_ami" "my_ami" {
#      most_recent      = true
#      #name_regex       = "^mavrick"
#      owners           = ["721834156908"]
# }


# resource "aws_instance" "web-1" {
#     ami = var.imagename
#     #ami = "ami-0d857ff0f5fc4e03b"
#     #ami = "${data.aws_ami.my_ami.id}"
#     availability_zone = "us-east-1a"
#     instance_type = "t2.micro"
#     key_name = "LaptopKey"
#     subnet_id = "${aws_subnet.subnet1-public.id}"
#     vpc_security_group_ids = ["${aws_security_group.allow_all.id}"]
#     associate_public_ip_address = true	
#     tags = {
#         Name = "Server-1"
#         Env = "Prod"
#         Owner = "Sree"
# 	CostCenter = "ABCD"
#     }
# }

##output "ami_id" {
#  value = "${data.aws_ami.my_ami.id}"
#}
#!/bin/bash
# echo "Listing the files in the repo."
# ls -al
# echo "+++++++++++++++++++++++++++++++++++++++++++++++++++++"
# echo "Running Packer Now...!!"
# packer build -var=aws_access_key=AAAAAAAAAAAAAAAAAA -var=aws_secret_key=BBBBBBBBBBBBB packer.json
#packer validate --var-file creds.json packer.json
#packer build --var-file creds.json packer.json
#packer.exe build --var-file creds.json -var=aws_access_key=AAAAAAAAAAAAAAAAAA -var=aws_secret_key=BBBBBBBBBBBBB packer.json
# echo "+++++++++++++++++++++++++++++++++++++++++++++++++++++"
# echo "Running Terraform Now...!!"
# terraform init
# terraform apply --var-file terraform.tfvars -var="aws_access_key=AAAAAAAAAAAAAAAAAA" -var="aws_secret_key=BBBBBBBBBBBBB" --auto-approve
#https://discuss.devopscube.com/t/how-to-get-the-ami-id-after-a-packer-build/36

==================================================

above code open vscode editor
expect main.tf , output.tfx, terraform.tvars,variable.tf remove all the files

the diff b/w var.tf and terraform.tfvars (is we can change the dynamic code only in .tfvars insted of changing the total code

the procedure is
main.tf ==> variable.tf => terra.tfvars (we don't change the main code we only change in tfvars)
======================================terraform real time project udemy================
https://github.com/Sanjeev-Thiyagarajan/Terraform-Crash-Course
=============================================================================
from now again madhu


terraform init
terraform plan -var_file terraform.tfvars --auto-approve

** must be take care of state file

types of files
.tf
.tfvars
.state

real time

clone github repo
https://github.com/mavrick202/terraformsingleinstance

rm -rf docker.service jenkibuildscript packer.json 

after
the main code will be there in main.tf file

flow
main to variable.tf --> .tfvars
in output file remove all the existing data and add the below code to get vpc name

output "vpc_name" {
  description = "list of vpc name"
  value = ["${aws_vpc.default.tags.Name}"]
}


"change terraform.tfvars into prod.tfvars"

in that file give ur aws acceesskey & secreat key


*** now we have to run our dry run
terraform plan --var-file prod.tfvars

terraform apply --var-file prod.tfvars (it will apply on real time on to our servers)

** to know what we are deployed we can known bt
terraform state list

* terraform show (it will clearly explain the what we did in our operation)


** Note one folder inside we can't run multiple tfvar files bcoz state problem(it will overwrite the old data)


** to destory
terraform destory --var-file prod.tfvars

** now when we work on multiple tfvars we can use "workspace" its nothing but a git branch type

terraform workspace show

to create a new work space
terraform workspace new prod

terraform workspace list

terraform workspace new dev

terraform plan --var-file dev.tfvars (by using workspace we can use muktiple variable files)
terraform plan --var-file prod.tfvars (by using workspace we can use muktiple variable files)

Note "
never user workspace bcoz of thread(overwritten the all files) insted of we can use multiple folders


*** we never share or push a state file to github

now we copy our entire project and pasted in another location

now parent folder apply the terraform
now go to same child (note terraform.tfstate file must be there ) otherwise its duplicates your data

""" insted of coping everytime the .tfstate file we can use terraform state backend"""

we can use terraform back end
go to aws create aws s3 bucket

terraform {
  backend "s3" {
    bucket = "terrabackendraj"
    key    = "myterraform.tfstate"
    region = "us-east-1"
  }
}

ref url: https://github.com/mavrick202/terraformsingleinstance/blob/remotebackends3/main.tf


*** reference main.rf
#This Terraform Code Deploys Basic VPC Infra.
provider "aws" {
    access_key = "${var.aws_access_key}"
    secret_key = "${var.aws_secret_key}"
    region = "${var.aws_region}"
}

resource "aws_vpc" "default" {
    cidr_block = "${var.vpc_cidr}"
    enable_dns_hostnames = true
    tags = {
        Name = "${var.vpc_name}"
	Owner = "Sreeharsha Veerapalli"
	environment = "${var.environment}"
    }
}

resource "aws_internet_gateway" "default" {
    vpc_id = "${aws_vpc.default.id}"
	tags = {
        Name = "${var.IGW_name}"
    }
}

resource "aws_subnet" "subnet1-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet1_cidr}"
    availability_zone = "us-east-1a"

    tags = {
        Name = "${var.public_subnet1_name}"
    }
}

resource "aws_subnet" "subnet2-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet2_cidr}"
    availability_zone = "us-east-1b"

    tags = {
        Name = "${var.public_subnet2_name}"
    }
}

resource "aws_subnet" "subnet3-public" {
    vpc_id = "${aws_vpc.default.id}"
    cidr_block = "${var.public_subnet3_cidr}"
    availability_zone = "us-east-1c"

    tags = {
        Name = "${var.public_subnet3_name}"
    }
	
}


resource "aws_route_table" "terraform-public" {
    vpc_id = "${aws_vpc.default.id}"

    route {
        cidr_block = "0.0.0.0/0"
        gateway_id = "${aws_internet_gateway.default.id}"
    }

    tags = {
        Name = "${var.Main_Routing_Table}"
    }
}

resource "aws_route_table_association" "terraform-public" {
    subnet_id = "${aws_subnet.subnet1-public.id}"
    route_table_id = "${aws_route_table.terraform-public.id}"
}

resource "aws_security_group" "allow_all" {
  name        = "allow_all"
  description = "Allow all inbound traffic"
  vpc_id      = "${aws_vpc.default.id}"

  ingress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port       = 0
    to_port         = 0
    protocol        = "-1"
    cidr_blocks     = ["0.0.0.0/0"]
    }
}

terraform {
  backend "s3" {
    bucket = "terrabucketn1"
    key    = "myterraform.tfstate"
    region = "us-east-1"
  }
}


# data "aws_ami" "my_ami" {
#      most_recent      = true
#      #name_regex       = "^mavrick"
#      owners           = ["721834156908"]
# }


# resource "aws_instance" "web-1" {
#     ami = var.imagename
#     #ami = "ami-0d857ff0f5fc4e03b"
#     #ami = "${data.aws_ami.my_ami.id}"
#     availability_zone = "us-east-1a"
#     instance_type = "t2.micro"
#     key_name = "LaptopKey"
#     subnet_id = "${aws_subnet.subnet1-public.id}"
#     vpc_security_group_ids = ["${aws_security_group.allow_all.id}"]
#     associate_public_ip_address = true	
#     tags = {
#         Name = "Server-1"
#         Env = "Prod"
#         Owner = "Sree"
# 	CostCenter = "ABCD"
#     }
# }

##output "ami_id" {
#  value = "${data.aws_ami.my_ami.id}"
#}
#!/bin/bash
# echo "Listing the files in the repo."
# ls -al
# echo "+++++++++++++++++++++++++++++++++++++++++++++++++++++"
# echo "Running Packer Now...!!"
# packer build -var=aws_access_key=AAAAAAAAAAAAAAAAAA -var=aws_secret_key=BBBBBBBBBBBBB packer.json
#packer validate --var-file creds.json packer.json
#packer build --var-file creds.json packer.json
#packer.exe build --var-file creds.json -var=aws_access_key=AAAAAAAAAAAAAAAAAA -var=aws_secret_key=BBBBBBBBBBBBB packer.json
# echo "+++++++++++++++++++++++++++++++++++++++++++++++++++++"
# echo "Running Terraform Now...!!"
# terraform init
# terraform apply --var-file terraform.tfvars -var="aws_access_key=AAAAAAAAAAAAAAAAAA" -var="aws_secret_key=BBBBBBBBBBBBB" --auto-approve
#https://discuss.devopscube.com/t/how-to-get-the-ami-id-after-a-packer-build/36


============================ Terraform Dynamodblocking==================
When multiple enginers working on same project same files at that time we may face some problems due to conflicts on working on same files to avoid that cause create 
locking system

as of now assume i had configured terraform same project on my mac and aws ubuntu machine at that time we work on same project same file we may get conflict to overcome
we can use the locking system

open aws and launch ubuntu machine

create one private repo on github
create one file i ur terraform project as the 
.gitignore
.terraform
*.exe
efs.yml

rm -rf .git
git init
git remote add origin add private url
git status (now u will observer .terraform etc file will removed)

git add .
git commit -m "terra main code"
git push origin master

after pushing our code is: https://github.com/rajeshsingamsetti/terraformprivate/tree/master

Now go to ubuntu machine launch it

ssh-keygen
hit enter 3 times

cat /root/.ssh/id_rsa.pub

copy the total code and go to git that particular private repo and settings

left side click on deploy keys under ssh paste your copy code give any title u want 

come to ubuntu machine clone ur private repo
choose clone ssh ur github private repo (not http go with ssh)
git clone sshurl

for ubuntu create a new iam role for terraform

now we need to install aws cli on ubuntu machine

for ubuntu 18.03 install aws cli through

apt-get update -y
apt-get update install awscli
aws --version

go to aws create a user and add take acees key
aws configure

now go to our mac now according to code
create a bucket in s3 aws (in the name of our terraform code)
in mac
terraform init
terraform plan --var-file prod.tfvars (or terraform plan -var-file terraform.tfvars)
terraform apply

if any changes in mac commite it
git status

now come to ubuntu machine
cd project file
git pull sshurl master

terraform state list

Command 'terraform' not found, but can be installed with

terraform not found on ubuntu we need to install terraform on ubuntu
install on ubuntu
cd /usr/local/bin/
wget https://releases.hashicorp.com/terraform/0.13.5/terraform_0.13.5_linux_amd64.zip
unzip terraform_0.13.5_linux_amd64.zip 

cd terraformprivate/(our main git clone project on root)

terraform init
terraform state list

remove output.tfx and make it output.tf and paste the below code
ouput "vpc_name" {
  description = "list of vpc name"
  value = ["${aws_vpc.default.id}"]
}

after terraform init
terraform apply

git status (now output file will be changed)
git add . && git commit -m "changes"
git push origin master

go to github now the code is changed

Now come to mac user 
git pull https://github.com/rajeshsingamsetti/terraformprivate.git master(url of github master)

now we had chances that multiple people override for that we are using lock system


use the below code create a onefile in mac name it as a dynamodb.tf

# example.tf
# create a dynamodb table for locking the state file
resource "aws_dynamodb_table" "dynamodb-terraform-state-lock" {
  name = "terraform-state-lock-dynamo"
  hash_key = "LockID"
  read_capacity = 20
  write_capacity = 20
 
  attribute {
    name = "LockID"
    type = "S"
  }
 
  tags = {
    Name = "DynamoDB Terraform State Lock Table"
  }
}

now run terraform plan (it will create dynamodb table we can see that in terminal)
after plan success apply it
terraform apply

after go to aws dynamodb 
we will see on table in under dynamodb

after creating dynamo db table now you need to add 2 lines od code in your s3backend as it shown below like this

encrypt = true
dynamodb_table = "terraform-state-lock-dynamo"
    
now under main.tf under s3 file shold be like this

terraform {
  backend "s3" {
    bucket = "terrabucketn1"
    key    = "myterraform.tfstate"
    region = "us-east-1"
    encrypt = true
    dynamodb_table = "terraform-state-lock-dynamo"

  }
 }
 
 

after 
terraform apply (it will throgh error bcoz we need to intialize)
after intialize successfully change ur code small correction like add tags then apply it)
terraform apply
now go to aws dynamo db u will see one table means (dynamolock configure successfully)

now in ur mac user
git status
git add .
git commit -m  "dynamo lock"
git push origin master

Now go to ubunti user 

git pull git@github.com:rajeshsingamsetti/terraformprivate.git master


***** now go to mac user change the name or anything and save it

terraform apply (note now don't type yes)

now go to ubuntu server

terraform apply (you will see init if error comes init it after apply it now u can see that its locked)

*****now we will see the lock like this****
Error: Error locking state: Error acquiring the state lock: ConditionalCheckFailedException: The conditional request failed
Lock Info:
  ID:        57a7fa51-35e5-9969-d51f-ae6e6e897010
  Path:      terrabucketn1/myterraform.tfstate
  Operation: OperationTypeApply
  Who:       rajsingam@RAJs-MBP
  Version:   0.13.5
  Created:   2020-11-29 16:28:06.345226 +0000 UTC
  Info:      


Terraform acquires a state lock to protect the state from being written
by multiple users at the same time. Please resolve the issue above and try
again. For most commands, you can disable locking with the "-lock=false"
flag, but this is not recommended.
*******************************************************************
after yes
git add . && git commit -m "mac userdata"
git push origin master


now in ubutu 


git pull git@github.com:rajeshsingamsetti/terraformprivate.git master

change name or any thing 
terraform apply
don't type yes

now come to mac user type 
terraform apply

now we will get lock error on mac user also

** so now we will get lock in all user by using multiple admin we will work same time without any issues

in real time never give 
-lock=false
terraform apply -lock=false(it will cause issues)

===============================terraform data points=======================================================
terraform import => imports manually created resources in to configuration and we can manage it even delete it
terraform DataSources => let terraform know about the resources which are the not part of it
"to manage the existing resources but don't had an right of delete it"

"terraform refresh is used for refreshing of the state of terraform"

add this below code in ur main.tf file
it will fetch the exsiting vpc details

data "aws_vpc" "Rajvpc" {
  id = "vpc-0d143ca90e92391ad"
}
now run 
terraform refresh

***** note: once by using datasource vpc or anything is created its related all attributes are imported from that particular service like tagname,cidr_block,routetable_name.

by using data source we create vpc and one subnet

data "aws_vpc" "Rajvpc" {
  id = "vpc-0d143ca90e92391ad"
}

resource "aws_subnet" "rajvpcsubnet4-public" {
    vpc_id = "${data.aws_vpc.Rajvpc.id}"
    cidr_block = "10.0.4.0/24"
    availability_zone = "us-east-1a"

    tags = {
        Name = "Rajvpc-subnet-4"
    }
}

add above code in ur main.tf file

====================== to delete a specific resource from terraform========
terraform destroy -target aws_subnet.rajvpcsubnet4-public

to remove from state list (bcoz if u delete particulat subnet code also it exist on state to remove from state list also follow below procedure)
terraform state list

to remove from state list
terraform state rm aws_subnet.rajvpcsubnet4-public

===========================================================================================================================================================
					     Functions
without code duplication create subnets in different availability zones and diff cidr's

az = us-east-1a,us-east-1b,us-east-1c
cidrs = 10.1.1.0/24,10.1.2.0/24,10.1.3.0/24,10.1.4.0/24,10.1.5.0/24

to avoid code duplicate (pasting subnets multiple times) we can use terraform functions

to set variables on variables.tf file
variable "azs" {
  description = "Run the EC2 Instances in these Availability Zones"
  type = "list"
  default = ["us-east-1a", "us-east-1b", "us-east-1c"]
}
variable "cidrs" {
  description = "Cidr's for subnets"
  type = "list"
  default = ["10.1.1.0/24", "10.1.2.0/24", "10.1.3.0/24"]
}


main.tf 

ref url of functions:
https://www.terraform.io/docs/configuration/functions.html

in functions we use
length
count
element


terraform functions reference github url:
https://github.com/rajeshsingamsetti/terraformfunctions1/tree/master


=============================================terraform another functions======
lookups
conditional

null resource and taint usage
local-exec
remote exec
for_each
depends_on
locals
			lookup
without lookup if u run ur code in any another region it fails by using lookup your code will run in any regions 
https://github.com/rajeshsingamsetti/terraformfunctions1/tree/master

remove state files
and rename the dynamodb.tf to dynamo.tf1
and go to main.tf

comment the backend s3
# terraform {
#   backend "s3" {
#     bucket = "terrabucketn1"
#     key    = "myterraform.tfstate"
#     region = "us-east-1"
#     encrypt = true
#     dynamodb_table = "terraform-state-lock-dynamo"

#   }
# }

and ec2.tf the private subnet total bracket should be in comments we enough to public subnet

now by using lookups whereever the region will be there it will take automatically

ec2.tf
example: ami = "${lookup(var.amis, var.aws_region, "us-east-1")}"

in variable.tf

variable "aws_region" {}
variable "amis" {
    description = "AMIs by region"
    default = {
      us-east-1 = "ami-00ddb0e5626798373" # ubuntu 14.04 LTS(us region ami number give here)
      us-east-2 = "ami-0ebc8f6f580a04647" # ubuntu 14.04 LTS
    }
}

in main.tf file remove below code private nat remove
//private route
resource "aws_route_table_association" "terraform-private" {
    count = "${length(var.private-cidrs)}"
    subnet_id = "${element(aws_subnet.private-subnets.*.id, count.index)}"
    route_table_id = "${aws_route_table.terraform-private.id}"
}

//private routing table
resource "aws_route_table" "terraform-private" {
    vpc_id = "${aws_vpc.default.id}"

    route {
        cidr_block = "0.0.0.0/0"
        gateway_id = "${aws_nat_gateway.ngw.id}"
    }

    tags = {
        Name = "${var.Private_Routing_Table}"
    }
}

and rename the eip-nat.tfx (elastic ip rename the file)

go to terraform.tfvars
change the acees key and security key



terraform init 
terraform plan

after sucess run instance created ami it will take the region of us-east1

Conditional Expressions

refurl: https://www.terraform.io/docs/configuration/expressions.html

"environment" == "Prod" ? 3 : 1

give above line in ec2 under count 
count = "${var.environment == "Prod" ? 3 : 1}"

in main.tf also count change to above count variable type
in public subnets creation count give likke
count = 1
terraform plan 
-------------------------
local_exec
remote_exec


local_exec
when terraform execution perform some actions like add some data we use localexec
ex; create a one seperate file like :nullresource.tf
resource "null_resource" "localexec" {
    count = "${var.environment == "Prod" ? 3 : 1}"
    provisioner "local-exec" {
    command = <<-EOF
      echo "${element(aws_instance.public-instances.*.public_ip, count.index)}"  >> details.txt
    EOF
    }
}





now we r going to null resource

what is null resource:














































